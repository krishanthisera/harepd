package controllers

import (
	"context"
	"encoding/json"
	"fmt"
	"net"
	"sync"

	"code.unitiwireless.com/uniti-wireless/harepd/models"
	"github.com/sirupsen/logrus"
	grpc "google.golang.org/grpc"
	"google.golang.org/grpc/credentials"
)

//Logs for loging with logrus
var Logs *logrus.Logger

type messageServer struct {
	models.UnimplementedClusterInfoServer
	Mu      sync.Mutex
	Message string
	conf    *models.Config
}

// GetClusterInfo is generated by protocol buf. aka "protoc" to accommodate gRPC client requests
func (srv *messageServer) GetClusterInfo(ctx context.Context, client *models.WhatYouKnow) (*models.IKnow, error) {

	// Handelling Panics
	defer func() {
		if rec := recover(); rec != nil {
			Logs.Error("Error executing GetClusterInfo: ", rec)
		}
	}()

	enq, err := json.Marshal(client)
	if err != nil {
		Logs.Error(err)
	}
	//Struct should be a json string
	Logs.Info(fmt.Sprint("Inquiry received from : ", string(enq)))
	var info models.IKnow

	// // SQL Queries
	// // Masters
	masters, err := models.DB.Raw("SELECT conninfo FROM repmgr.nodes WHERE type = ? AND active = ?", "primary", "t").Rows()
	defer masters.Close()
	if err != nil {
		Logs.Error(err)
		return nil, err
	}

	//Slaves

	slaves, err := models.DB.Raw("SELECT conninfo FROM repmgr.nodes WHERE type = ? AND active = ?", "standby", "t").Rows()
	defer slaves.Close()
	if err != nil {
		Logs.Error(err)
		return nil, err
	}

	//Node IDs
	nodeID := models.DB.Raw("SELECT node_id FROM repmgr.nodes WHERE node_name = ?", srv.conf.Harepd.NodeName).Row()
	if nodeID == nil {
		Logs.Error(err)
		return nil, err
	}

	//Witness
	witness := models.DB.Raw("SELECT conninfo FROM repmgr.nodes WHERE type = ? AND active = ?", "witness", "t").Row()
	if witness == nil {
		Logs.Error(err)
		return nil, err
	}

	// Node IP
	info.Ip = srv.conf.Harepd.Grpc.BindAddress

	// Master Node
	for masters.Next() {
		var r string
		err := masters.Scan(&r)
		if err != nil {
			Logs.Error(err)
			return nil, err
		}
		info.Master = append(info.Master, models.IpScrapper(r)[0])
	}

	// Node ID
	var r int32
	err = nodeID.Scan(&r)
	if err != nil {
		Logs.Error(err)
		return nil, err
	}
	info.NodeId = r

	// Slaves
	for slaves.Next() {
		var r string
		err := slaves.Scan(&r)
		if err != nil {
			Logs.Error(err)
			return nil, err
		}
		info.Slaves = append(info.Slaves, models.IpScrapper(r)[0])
	}

	// Witness
	var w string
	err = witness.Scan(&w)
	if err != nil {
		Logs.Error(err)
		return nil, err
	}
	info.Witness = models.IpScrapper(w)[0]

	info.NodeName = srv.conf.Harepd.NodeName
	inf, err := json.Marshal(&info)

	//Should be a json string
	Logs.Info(fmt.Sprint("Response generated: ", string(inf)))

	// info.Ip = srv.conf.Harepd.Grpc.BindAddress
	// info.Master = append(info.Master, "10.0.01")
	// info.Slaves = append(info.Slaves, "10.0110101")
	// info.Witness = "10.1.1.1"
	// info.NodeId = 1
	// info.NodeName = srv.conf.Harepd.NodeName
	return &info, nil

}

//GrpcServer initiate the gRPC server components
func GrpcServer(conf models.Config) error {

	// Handelling Panics
	defer func() {
		if rec := recover(); rec != nil {
			Logs.Error("Grpc Server run into issue ", rec)
		}
	}()

	Logs = models.NewLogger(&conf)

	lis, err := net.Listen("tcp", fmt.Sprintf("%s:%d", conf.Harepd.Grpc.BindAddress, conf.Harepd.Grpc.BindPort))
	if err != nil {
		Logs.Error(err)
		return err
	}

	var opts []grpc.ServerOption
	if conf.Harepd.Grpc.TLS.Enabled {
		certFile := conf.Harepd.Grpc.TLS.Cert
		keyFile := conf.Harepd.Grpc.TLS.Key
		creds, err := credentials.NewServerTLSFromFile(certFile, keyFile)
		if err != nil {
			Logs.Error(err)
			return err
		}
		opts = []grpc.ServerOption{grpc.Creds(creds)}
	}

	grpcServer := grpc.NewServer(opts...)
	Logs.Info(grpcServer)
	models.RegisterClusterInfoServer(grpcServer, newServer(&conf))
	grpcServer.Serve(lis)

	return nil
}

func newServer(conf *models.Config) *messageServer {
	srv := &messageServer{}
	srv.Message = "Open"
	srv.conf = conf
	return srv
}
